<!DOCTYPE html>
<html lang=en>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="爬虫：通过编写程序来获取互联网上的资源 初始爬虫爬虫入门要求：用程序模拟浏览器，输入一个网址，从该网址中获取到资源或者内容 1234567891011 # 1.爬虫获取百度页面信息from urllib.request import urlopenurl &#x3D; &amp;#x27;http:&#x2F;&#x2F;www.baidu.com&amp;#x27;resp &#x3D; urlopen(url)# print(resp.read()">
<meta property="og:type" content="article">
<meta property="og:title" content="python spider">
<meta property="og:url" content="http://p5ych2022.github.io/2023/05/22/python-spider/index.html">
<meta property="og:site_name" content="psych&#39;s blog">
<meta property="og:description" content="爬虫：通过编写程序来获取互联网上的资源 初始爬虫爬虫入门要求：用程序模拟浏览器，输入一个网址，从该网址中获取到资源或者内容 1234567891011 # 1.爬虫获取百度页面信息from urllib.request import urlopenurl &#x3D; &amp;#x27;http:&#x2F;&#x2F;www.baidu.com&amp;#x27;resp &#x3D; urlopen(url)# print(resp.read()">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/p5ych2022/IHS@master/img/image-20230107061032489-1024x253.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/p5ych2022/IHS@master/img/image-20230107061755167.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/p5ych2022/IHS@master/img/image-20230107214041509-1024x208.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/p5ych2022/IHS@master/img/image-20230107214112292.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/p5ych2022/IHS@master/img/image-20230108222632061-1024x127.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/p5ych2022/IHS@master/img/image-20230110232047495-1024x438.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/p5ych2022/IHS@master/img/image-20230111001434047-1024x829.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/p5ych2022/IHS@master/img/image-20230111001456613-1024x664.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/p5ych2022/IHS@master/img/image-20230111001952355.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/p5ych2022/IHS@master/img/image-20230111004110413.png">
<meta property="article:published_time" content="2023-05-22T14:33:09.000Z">
<meta property="article:modified_time" content="2023-08-16T15:23:39.292Z">
<meta property="article:author" content="psych">
<meta property="article:tag" content="python">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/p5ych2022/IHS@master/img/image-20230107061032489-1024x253.png">
    
    
      
        
          <link rel="shortcut icon" href="/images/favicon.ico">
        
      
      
        
          <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
        
      
    
    <!-- title -->
    <title>python spider</title>
    <!-- async scripts -->
    <!-- Google Analytics -->


    <!-- Umami Analytics -->


    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
<meta name="generator" content="Hexo 6.3.0"></head>

<body class="max-width mx-auto px3 ltr">
    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="Menu"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="Top" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fa-solid fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Article</a></li><!--
     --><!--
       --><li><a href="/tags/">Tag</a></li><!--
     --><!--
       --><li><a href="/categories/">Category</a></li><!--
     --><!--
       --><li><a href="/search/">Search</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        <li><a class="icon" aria-label="Previous post" href="/2023/06/02/ciscn-2023-web-%E9%83%A8%E5%88%86writeup/"><i class="fa-solid fa-chevron-left" aria-hidden="true" onmouseover="$('#i-prev').toggle();" onmouseout="$('#i-prev').toggle();"></i></a></li>
        
        
        <li><a class="icon" aria-label="Next post" href="/2023/05/18/%E7%AE%97%E4%BA%86%E5%90%97/"><i class="fa-solid fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="Back to top" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="Share post" href="#"><i class="fa-solid fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">Previous post</span>
      <span id="i-next" class="info" style="display:none;">Next post</span>
      <span id="i-top" class="info" style="display:none;">Back to top</span>
      <span id="i-share" class="info" style="display:none;">Share post</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://p5ych2022.github.io/2023/05/22/python-spider/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://p5ych2022.github.io/2023/05/22/python-spider/&text=python spider"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://p5ych2022.github.io/2023/05/22/python-spider/&title=python spider"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://p5ych2022.github.io/2023/05/22/python-spider/&is_video=false&description=python spider"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=python spider&body=Check out this article: http://p5ych2022.github.io/2023/05/22/python-spider/"><i class="fa-solid fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://p5ych2022.github.io/2023/05/22/python-spider/&title=python spider"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://p5ych2022.github.io/2023/05/22/python-spider/&title=python spider"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://p5ych2022.github.io/2023/05/22/python-spider/&title=python spider"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://p5ych2022.github.io/2023/05/22/python-spider/&title=python spider"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://p5ych2022.github.io/2023/05/22/python-spider/&name=python spider&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://p5ych2022.github.io/2023/05/22/python-spider/&t=python spider"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    
    
      <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9D%E5%A7%8B%E7%88%AC%E8%99%AB"><span class="toc-number">1.</span> <span class="toc-text">初始爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8"><span class="toc-number">1.1.</span> <span class="toc-text">爬虫入门</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#web%E8%AF%B7%E6%B1%82%E8%BF%87%E7%A8%8B%E5%89%96%E6%9E%90"><span class="toc-number">1.2.</span> <span class="toc-text">web请求过程剖析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#http%E5%8D%8F%E8%AE%AE"><span class="toc-number">1.3.</span> <span class="toc-text">http协议</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#requests%E5%85%A5%E9%97%A8"><span class="toc-number">1.4.</span> <span class="toc-text">requests入门</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%88%AC%E5%8F%96%E7%99%BE%E5%BA%A6%E7%BF%BB%E8%AF%91%E6%95%B0%E6%8D%AE"><span class="toc-number">1.5.</span> <span class="toc-text">爬取百度翻译数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A1%A5%EF%BC%9A%E7%BC%96%E7%A0%81%E4%B8%8E%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99"><span class="toc-number">1.6.</span> <span class="toc-text">补：编码与文件读写</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%A7%A3-%E6%9E%90%E6%A6%82%E8%BF%B0"><span class="toc-number">2.</span> <span class="toc-text">数据解 析概述</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#re%E8%A7%A3%E6%9E%90"><span class="toc-number">2.1.</span> <span class="toc-text">re解析</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Regular-Expression-re"><span class="toc-number">2.1.1.</span> <span class="toc-text">Regular Expression(re)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#re%E6%A8%A1%E5%9D%97"><span class="toc-number">2.1.2.</span> <span class="toc-text">re模块</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#re%E6%A8%A1%E5%9D%97%E5%AE%9E%E6%88%98"><span class="toc-number">2.1.3.</span> <span class="toc-text">re模块实战</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E7%88%AC%E5%8F%96%E8%B1%86%E7%93%A3%E6%8E%92%E8%A1%8C%E6%A6%9Ctop250"><span class="toc-number">2.1.3.1.</span> <span class="toc-text">爬取豆瓣排行榜top250</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E7%88%AC%E5%8F%96%E7%94%B5%E5%BD%B1%E5%A4%A9%E5%A0%82%E4%BF%A1%E6%81%AF"><span class="toc-number">2.1.3.2.</span> <span class="toc-text">爬取电影天堂信息</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#bs4%E8%A7%A3%E6%9E%90"><span class="toc-number">2.2.</span> <span class="toc-text">bs4解析</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BB%83%E4%B9%A0"><span class="toc-number">2.2.1.</span> <span class="toc-text">练习</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%8C%97%E4%BA%AC%E6%96%B0%E5%8F%91%E5%9C%B0%E7%88%AC%E5%8F%96%E8%8F%9C%E4%BB%B7"><span class="toc-number">2.2.1.1.</span> <span class="toc-text">北京新发地爬取菜价</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E4%BC%98%E7%BE%8E%E7%BE%8E%E5%9B%BE%E5%BA%93%E5%9B%BE%E7%89%87"><span class="toc-number">2.2.1.2.</span> <span class="toc-text">优美美图库图片</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#xpath%E8%A7%A3%E6%9E%90"><span class="toc-number">2.3.</span> <span class="toc-text">xpath解析</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80"><span class="toc-number">2.3.0.1.</span> <span class="toc-text">基础</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%AE%9E%E6%88%98"><span class="toc-number">2.3.0.2.</span> <span class="toc-text">实战</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Requests-%E8%BF%9B%E9%98%B6"><span class="toc-number"></span> <span class="toc-text">Requests 进阶</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%84%E7%90%86cookie"><span class="toc-number">1.</span> <span class="toc-text">处理cookie</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%98%B2%E7%9B%97%E9%93%BE"><span class="toc-number">2.</span> <span class="toc-text">防盗链</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%9B%97%E9%93%BE"><span class="toc-number">2.0.1.</span> <span class="toc-text">盗链</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%98%B2%E7%9B%97%E9%93%BE%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="toc-number">2.0.2.</span> <span class="toc-text">防盗链的工作原理</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%90%86"><span class="toc-number">3.</span> <span class="toc-text">代理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%BC%E5%90%88%E8%AE%AD%E7%BB%83%EF%BC%88wyy%EF%BC%89"><span class="toc-number">4.</span> <span class="toc-text">综合训练（wyy）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%88%AC%E5%8F%96%E7%BD%91%E6%98%93%E4%BA%91%E7%83%AD%E8%AF%84"><span class="toc-number">4.0.1.</span> <span class="toc-text">爬取网易云热评</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8F%90%E9%AB%98%E7%88%AC%E8%99%AB%E6%95%88%E7%8E%87"><span class="toc-number"></span> <span class="toc-text">提高爬虫效率</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E7%BA%BF%E7%A8%8B"><span class="toc-number">0.1.</span> <span class="toc-text">多线程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E8%BF%9B%E7%A8%8B"><span class="toc-number">0.2.</span> <span class="toc-text">多进程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%92%8C%E8%BF%9B%E7%A8%8B%E6%B1%A0"><span class="toc-number">0.3.</span> <span class="toc-text">线程池和进程池</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%8F%E7%A8%8B"><span class="toc-number">0.4.</span> <span class="toc-text">协程</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E9%98%BB%E5%A1%9E%E7%8A%B6%E6%80%81"><span class="toc-number">0.4.0.1.</span> <span class="toc-text">阻塞状态</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%8D%8F%E7%A8%8B-1"><span class="toc-number">0.4.0.2.</span> <span class="toc-text">协程</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%BC%82%E6%AD%A5%E5%8D%8F%E7%A8%8B"><span class="toc-number">0.4.0.3.</span> <span class="toc-text">多任务异步协程</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BC%82%E6%AD%A5http%E8%AF%B7%E6%B1%82aiohttp%E6%A8%A1%E5%9D%97"><span class="toc-number">0.5.</span> <span class="toc-text">异步http请求aiohttp模块</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%8A%93%E5%8F%96%E7%99%BE%E5%BA%A6%E5%B0%8F%E8%AF%B4-dd"><span class="toc-number">0.5.1.</span> <span class="toc-text">抓取百度小说(dd)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%8A%93%E5%8F%96%E8%A7%86%E9%A2%91%E7%BD%91%E7%AB%99-dd"><span class="toc-number">0.5.2.</span> <span class="toc-text">抓取视频网站(dd)</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#selenium"><span class="toc-number"></span> <span class="toc-text">_selenium</span></a>
      </div>
    
  </span>
</div>

    
    <div class="content index py4 ">
        
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle p-name" itemprop="name headline">
        python spider
    </h1>



    <div class="meta">
      <span class="author p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span class="p-name" itemprop="name">psych</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2023-05-22T14:33:09.000Z" class="dt-published" itemprop="datePublished">2023-05-22</time>
        
      
    </div>


      
    <div class="article-category">
        <i class="fa-solid fa-archive"></i>
        <a class="category-link" href="/categories/web/">web</a> › <a class="category-link" href="/categories/web/web%E5%9F%BA%E7%A1%80/">web基础</a>
    </div>


      
    <div class="article-tag">
        <i class="fa-solid fa-tag"></i>
        <a class="p-category" href="/tags/python/" rel="tag">python</a>
    </div>


    </div>
  </header>
  

  <div class="content e-content" itemprop="articleBody">
    <p>爬虫：通过编写程序来获取互联网上的资源</p>
<h3 id="初始爬虫"><a href="#初始爬虫" class="headerlink" title="初始爬虫"></a>初始爬虫</h3><h4 id="爬虫入门"><a href="#爬虫入门" class="headerlink" title="爬虫入门"></a>爬虫入门</h4><p>要求：用程序模拟浏览器，输入一个网址，从该网址中获取到资源或者内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"> # 1.爬虫获取百度页面信息</span><br><span class="line">from urllib.request import urlopen</span><br><span class="line"></span><br><span class="line">url = &#x27;http://www.baidu.com&#x27;</span><br><span class="line">resp = urlopen(url)</span><br><span class="line"></span><br><span class="line"># print(resp.read().decode(&quot;utf-8&quot;))</span><br><span class="line"></span><br><span class="line">with open(&#x27;mybaidu.html&#x27;, mode=&#x27;w&#x27;, encoding=&#x27;utf-8&#x27;) as f:      #加上 encoding=&#x27;utf-8&#x27;，以utf-8写入文件，否则默认gbk(windows默认gbk)写入，就会乱码</span><br><span class="line">    f.write(resp.read().decode(&quot;utf-8&quot;))    # 获取网页源代码</span><br><span class="line">print(&#x27;ok!&#x27;)</span><br></pre></td></tr></table></figure>

<h4 id="web请求过程剖析"><a href="#web请求过程剖析" class="headerlink" title="web请求过程剖析"></a>web请求过程剖析</h4><ul>
<li>1. 服务器渲染：在服务器那边把数据和html整合在一起，统一返回给浏览器 注： 在页面源代码中，看得到数据</li>
<li>2. 客户端渲染： 第一次请求只要一个html骨架，第二次请求拿到数据，并进行数据展示注：在页面源代码中，看不到数据</li>
</ul>
<h4 id="http协议"><a href="#http协议" class="headerlink" title="http协议"></a>http协议</h4><p><strong>请求头</strong>中常见的一些重要内容（爬虫需要）</p>
<ul>
<li>User-agent ： 请求载体的身份标识（用啥发送的请求）</li>
<li>Referer ： _防盗链_（这次请求是从哪个页面来的？反爬会用到）</li>
<li>cookie ： 本地字符串数据信息（用户登录信息，反爬的token）</li>
</ul>
<p><strong>响应头</strong>中的一些重要内容：</p>
<ul>
<li>cookie ： 本地字符串数据信息（用户登录信息，反爬的cookie）</li>
<li>各种神奇的莫名其妙的字符串（这个需要经验了，一般都是token字样，防止各种攻击和反爬）</li>
</ul>
<h4 id="requests入门"><a href="#requests入门" class="headerlink" title="requests入门"></a>requests入门</h4><p>requests不是python自带的模块，需要自行安装</p>
<img src="https://cdn.jsdelivr.net/gh/p5ych2022/IHS@master/img/image-20230107061032489-1024x253.png" style="zoom: 67%;" />

<p>在pycharm里面自带的terminal执行命令<code>pip install requests</code> 注意，如果pip命令执行不了，就是环境变量没配置好，或者python版本太低，建议用python3.8</p>
<img src="https://cdn.jsdelivr.net/gh/p5ych2022/IHS@master/img/image-20230107061755167.png" style="zoom:67%;" />

<p>什么也不加，就<code>print(resp)</code>就会返回状态码</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line"></span><br><span class="line">headers = &#123;</span><br><span class="line"> # &#x27;Accept&#x27;: &quot;text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8&quot;,</span><br><span class="line"> # &#x27;Accept-Language&#x27;: &quot;zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2&quot;,</span><br><span class="line"> &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:108.0) Gecko/20100101 Firefox/108.0&quot;,</span><br><span class="line"> # &#x27;Accept-Encoding&#x27;: &#x27;gzip, deflate&#x27;,</span><br><span class="line"> &#x27;cookie&#x27;: &#x27;***&#x27;     #cookie加上才能爬出来，否则被ban，cookie最好看bp里面的，浏览器上的格式啥的可能不对。</span><br><span class="line"> &#125;</span><br><span class="line">url = &#x27;https://www.baidu.com/s?wd=aimer&#x27;</span><br><span class="line">resp = requests.get(url, headers=headers)</span><br><span class="line">print(resp)</span><br><span class="line">print(resp.content.decode(&#x27;utf-8&#x27;))  #拿到页面源代码</span><br></pre></td></tr></table></figure>

<h4 id="爬取百度翻译数据"><a href="#爬取百度翻译数据" class="headerlink" title="爬取百度翻译数据"></a>爬取百度翻译数据</h4><p>在百度翻译里面输入dog查询，network里面有一个包</p>
<img src="https://cdn.jsdelivr.net/gh/p5ych2022/IHS@master/img/image-20230107214041509-1024x208.png" style="zoom:67%;" />

<p>效应数据就是想要的翻译：</p>
<img src="https://cdn.jsdelivr.net/gh/p5ych2022/IHS@master/img/image-20230107214112292.png" style="zoom:67%;" />

<p>也就是说，<code>url=‘https://fanyi.baidu.com/sug’</code></p>
<p>请求，kw&#x3D;’dog’</p>
<p>响应就是需要的数据</p>
<p>用python实现：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">serc = input(&#x27;请输入你要翻译的单词：&#x27;.strip())</span><br><span class="line">url = &#x27;https://fanyi.baidu.com/sug&#x27;</span><br><span class="line">data = &#123;</span><br><span class="line">    &#x27;kw&#x27;: serc</span><br><span class="line">&#125;</span><br><span class="line">#发送post请求，发送的数据必须在字典中，通过data传递</span><br><span class="line">resp = requests.post(url, data=data)</span><br><span class="line">print(resp.json())   #将服务器返回的内容直接处理成json() =&gt; dict</span><br></pre></td></tr></table></figure>

<p>同理，爬取豆瓣排行榜信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#爬取豆瓣排行榜信息</span><br><span class="line">import requests</span><br><span class="line">url = &#x27;https://movie.douban.com/j/chart/top_list&#x27;</span><br><span class="line">params = &#123;</span><br><span class="line">    &#x27;type&#x27;: &#x27;24&#x27;,</span><br><span class="line">    &#x27;interval_id&#x27;: &#x27;100:90&#x27;,</span><br><span class="line">    &#x27;action&#x27;: &#x27;0&#x27;,                             #把get参数重新封装一下</span><br><span class="line">    &#x27;start&#x27;: &#x27;0&#x27;,</span><br><span class="line">    &#x27;limit&#x27;: &#x27;20&#x27;</span><br><span class="line">&#125;</span><br><span class="line">headers = &#123;</span><br><span class="line">&#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:108.0) Gecko/20100101 Firefox/108.0&#x27;              #一般加上UA否则可能会被反爬</span><br><span class="line">&#125; </span><br><span class="line">resp = requests.get(url, params=params, headers=headers)</span><br><span class="line">print(resp.json())</span><br><span class="line">resp.close()             #关掉这个response，否则可能请求次数过多，后期会出现一些问题</span><br></pre></td></tr></table></figure>

<h4 id="补：编码与文件读写"><a href="#补：编码与文件读写" class="headerlink" title="补：编码与文件读写"></a>补：编码与文件读写</h4><p>编码：</p>
<p>encode() -&gt;编码，把汉字编码成字符</p>
<p>decode() -&gt; 解码，把字符解码成为汉字</p>
<h3 id="数据解-析概述"><a href="#数据解-析概述" class="headerlink" title="数据解 析概述"></a>数据解 析概述</h3><p>大多数情况下我们不需要所有的数据，而只需要数据里面的很少一部分，这就涉及到数据提取问题。</p>
<p>主要有三种解析方式：</p>
<ul>
<li>re解析 （效率高） re -》regular expression[正则]</li>
<li>bs4解析 （速度快）</li>
<li>xpath解析 （流行）</li>
</ul>
<h4 id="re解析"><a href="#re解析" class="headerlink" title="re解析"></a>re解析</h4><h5 id="Regular-Expression-re"><a href="#Regular-Expression-re" class="headerlink" title="Regular Expression(re)"></a>Regular Expression(re)</h5><p>正则表达式：元字符+量词</p>
<p>元字符：具有固定含义的特殊符号</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">.     匹配换行符以外的任意字符</span><br><span class="line">\w    匹配数字字母下划线</span><br><span class="line">\s    匹配任意空白符</span><br><span class="line">\d    匹配数字</span><br><span class="line">\n    匹配一个换行符</span><br><span class="line">\t    匹配一个制表符</span><br><span class="line"></span><br><span class="line">^    匹配字符串的开始</span><br><span class="line">$    匹配字符串的结尾</span><br><span class="line"></span><br><span class="line">\W   匹配非字母数字下划线</span><br><span class="line">\D   匹配非数字</span><br><span class="line">\S   匹配非空白符</span><br><span class="line"></span><br><span class="line">ab  匹配字符a或者字符b</span><br><span class="line">()   匹配括号内的表达式，也表示一个组</span><br><span class="line">[..] 匹配字符组中的字符</span><br><span class="line">[^..]匹配除了字符组中字符的所有字符</span><br></pre></td></tr></table></figure>

<p>量词：控制前面的元字符出现的次数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">*     重复零次或者更多次</span><br><span class="line">+     重复一次或者更多次</span><br><span class="line">?     重复零次或者一次</span><br><span class="line">&#123;n&#125;   重复n次</span><br><span class="line">&#123;n,&#125;  重复n次或者更多次</span><br><span class="line">&#123;n,m&#125; 重复n到m次</span><br></pre></td></tr></table></figure>

<p><strong>贪婪匹配和惰性匹配</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">.*    贪婪匹配</span><br><span class="line">.*?   惰性匹配         有种负负得正的感觉     </span><br></pre></td></tr></table></figure>

<p>例：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">玩儿吃鸡游戏，什么游戏最好玩，吃鸡游戏最好玩！</span><br><span class="line"></span><br><span class="line">匹配   玩儿.?游戏    可能有以下结果</span><br><span class="line">玩儿吃鸡游戏</span><br><span class="line">玩儿吃鸡游戏，什么游戏</span><br><span class="line">玩儿吃鸡游戏，什么游戏最好玩，吃鸡游戏</span><br><span class="line"></span><br><span class="line">那么：</span><br><span class="line"> .*?   惰性匹配             中间匹配字符尽可能少，所以匹配第一个</span><br><span class="line"> .*    贪婪匹配             中间匹配字符尽可能多，所以匹配最后一个</span><br></pre></td></tr></table></figure>

<h5 id="re模块"><a href="#re模块" class="headerlink" title="re模块"></a>re模块</h5><p>在python中使用正则表达式，需要借助re模块</p>
<p>re模块有以下这些功能需要了解：</p>
<ul>
<li>findall 查找所有，返回list</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line">lst = re.findall(&quot;m&quot;, &quot;moi le fo len,moi ni mei!&quot;)</span><br><span class="line">print(lst)   #[&#x27;m&#x27;, &#x27;m&#x27;, &#x27;m&#x27;]</span><br><span class="line">lst = re.findall(r&quot;\d+&quot;,&#x27;5点之前，你要给我5000万！&#x27;)</span><br><span class="line">print(lst)   #[&#x27;5&#x27;, &#x27;5000&#x27;]</span><br></pre></td></tr></table></figure>

<ul>
<li>search 会进行匹配，但是如果匹配到了第一个结果，就会返回这个结果，如果匹配不上就会返回none</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#search返回的也是match对象，需要.group()来拿数据;   并且只会返回一个数据</span><br><span class="line">import re</span><br><span class="line">s = re.search(r&quot;\d+&quot;,&#x27;5点之前，你要给我5000万！&#x27;)</span><br><span class="line">print(s.group())</span><br></pre></td></tr></table></figure>

<ul>
<li>match 只能从字符串的开头进行匹配</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#match 只能从头匹配并且返回的也是match对象，需要.group()来拿数据</span><br><span class="line">import re</span><br><span class="line">s = re.match(r&quot;\d+&quot;, &#x27;5点之前，你要给我5000万！&#x27;)</span><br><span class="line">print(s.group())</span><br></pre></td></tr></table></figure>

<ul>
<li>finditer，和findall差不多，只不过返回的是<strong>迭代器</strong>（重点）</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#finditer:匹配字符串中所有内容[返回迭代器]，要从迭代器中拿到内容，需要 .group()</span><br><span class="line">   import re</span><br><span class="line">   it = re.finditer(r&quot;\d+&quot;,&#x27;5点之前，你要给我5000万！&#x27;)</span><br><span class="line">   for i in it:</span><br><span class="line">       print(i.group())</span><br></pre></td></tr></table></figure>

<ul>
<li>预加载正则表达式</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line">obj = re.compile(r&quot;\d+&quot;)          #预先加载这个正则表达式，可能会效率更高一点</span><br><span class="line">ret = obj.finditer(&#x27;5点之前，你要给我5000万！&#x27;)</span><br><span class="line">for i in ret:</span><br><span class="line">    print(ret.group())</span><br></pre></td></tr></table></figure>

<ul>
<li>从正则中进一步提取内容 格式 ： <code>(?P&lt;分组名字&gt;正则匹配式)</code> 可以单独从正则匹配的内容中进一步提取内容</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line">s = &#x27;&#x27;&#x27;          #\&#x27;&#x27;&#x27;可以换行写语句，而不用 /</span><br><span class="line">&lt;div class= &#x27;jay&#x27;&gt;&lt;span id= &#x27;1&#x27;&gt;哈哈哈&lt;/span&gt;&lt;/div&gt;</span><br><span class="line">&lt;div class= &#x27;jj&#x27;&gt;&lt;span id= &#x27;2&#x27;&gt;呵呵呵呵&lt;/span&gt;&lt;/div&gt;</span><br><span class="line">&lt;div class= &#x27;jony&#x27;&gt;&lt;span id= &#x27;3&#x27;&gt;嘿嘿&lt;/span&gt;&lt;/div&gt;</span><br><span class="line">&lt;div class= &#x27;jan&#x27;&gt;&lt;span id= &#x27;4&#x27;&gt;略略略略略&lt;/span&gt;&lt;/div&gt;</span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line"># obj = re.compile(r&quot;&lt;div class= &#x27;.*?&#x27;&gt;&lt;span id= &#x27;\d&#x27;&gt;.*?&lt;/span&gt;&lt;/div&gt;&quot;,re.S)</span><br><span class="line"># re.S是一种flags，作用是让.可以匹配换行符【防止源码有换行之类的情况】</span><br><span class="line">#上面这种写法可以匹配一整个html标签，但我们只想要后面的内容</span><br><span class="line">obj = re.compile(r&quot;&lt;div class= &#x27;.*?&#x27;&gt;&lt;span id= &#x27;\d&#x27;&gt;(?P&lt;语气词&gt;.*?)&lt;/span&gt;&lt;/div&gt;&quot;,re.S)</span><br><span class="line">result = obj.finditer(s)</span><br><span class="line">for it in result:</span><br><span class="line">    print(it.group(&#x27;语气词&#x27;))</span><br></pre></td></tr></table></figure>

<h5 id="re模块实战"><a href="#re模块实战" class="headerlink" title="re模块实战"></a>re模块实战</h5><h6 id="爬取豆瓣排行榜top250"><a href="#爬取豆瓣排行榜top250" class="headerlink" title="爬取豆瓣排行榜top250"></a>爬取豆瓣排行榜top250</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line">import csv</span><br><span class="line">for i in range(0, 10):</span><br><span class="line">    pages = 25 * i</span><br><span class="line">    url = &#x27;https://movie.douban.com/top250?start=&#x27;+str(pages)</span><br><span class="line">    headers = &#123;</span><br><span class="line">        &#x27;Cookie&#x27;: &#x27;bid=8UHUa3t6pKo; douban-fav-remind=1; __gads=ID=e7fe6811345277f9-22334e02c7d800b1:T=1670572592:RT=1670572592:S=ALNI_MZUJr_wSNzn771scrDXrECeoFN_SQ; __gpi=UID=00000b8ccfe9bf56:T=1670572592:RT=1673171396:S=ALNI_MadQPKn4grfVwodxBoEiw3Cune7sg; __utma=30149280.547815370.1670572596.1673113847.1673171401.4; __utmz=30149280.1673109963.2.2.utmcsr=cn.bing.comutmccn=(referral)utmcmd=referralutmcct=/; ll=&quot;118318&quot;; _pk_ref.100001.4cf6=%5B%22%22%2C%22%22%2C1673171400%2C%22https%3A%2F%2Fwww.douban.com%2F%22%5D; _pk_id.100001.4cf6=dd7c66dd3123a3b3.1673109976.3.1673171400.1673113847.; __utma=223695111.508457728.1673109977.1673113847.1673171401.3; __utmz=223695111.1673109977.1.1.utmcsr=douban.comutmccn=(referral)utmcmd=referralutmcct=/; __yadk_uid=Sb30wsdUmpnizO3OWCQCUIUdU3GLTcu6; __utmc=30149280; __utmc=223695111; ap_v=0,6.0&#x27;,</span><br><span class="line">        &#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:108.0) Gecko/20100101 Firefox/108.0&#x27;</span><br><span class="line">    &#125;</span><br><span class="line">    resp = requests.get(url, headers=headers)</span><br><span class="line">    s = resp.content.decode(&#x27;utf-8&#x27;)</span><br><span class="line">    #print(s)</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">     &lt;div class=&quot;pic&quot;&gt;</span><br><span class="line">                        &lt;em class=&quot;&quot;&gt;1&lt;/em&gt;</span><br><span class="line">                        &lt;a href=&quot;https://movie.douban.com/subject/1292052/&quot;&gt;</span><br><span class="line">                            &lt;img width=&quot;100&quot; alt=&quot;肖申克的救赎&quot; src=&quot;https://cdn.jsdelivr.net/gh/p5ych2022/IHS@master/img/p480747492.jpg&quot; class=&quot;&quot;&gt;</span><br><span class="line">                        &lt;/a&gt;</span><br><span class="line">                    &lt;/div&gt;</span><br><span class="line">    &quot;&quot;&quot;</span><br><span class="line">    #obj = re.compile(r&#x27;&lt;div class=&quot;pic&quot;&gt;.*?&lt;em class=&quot;&quot;&gt;(?P&lt;id&gt;\d)&lt;/em&gt;.*?&lt;a href=&quot;./*&quot;&gt;.*?&lt;img width=&quot;\d&quot; alt=&quot;(?P&lt;name&gt;.*?)&quot; src=&quot;.*?&quot; class=&quot;&quot;&gt;.*?&lt;/a&gt;.*?&lt;/div&gt;&#x27;, re.S)</span><br><span class="line">    obj = re.compile(r&#x27;&lt;div class=&quot;pic&quot;&gt;.*?&lt;em class=&quot;&quot;&gt;(?P&lt;id&gt;\d+)&lt;/em&gt;.*?&lt;a href=.*?alt=&quot;(?P&lt;name&gt;.*?)&quot;.*?&lt;/div&gt;&#x27;, re.S)</span><br><span class="line">    result = obj.finditer(s)</span><br><span class="line">#导入CSV文件中，方便后续查找</span><br><span class="line">    f = open(&#x27;douban.csv&#x27;, mode=&#x27;a&#x27;)</span><br><span class="line">    csvwriter = csv.writer(f)</span><br><span class="line">    for it in result:</span><br><span class="line">        #print(it.group(&#x27;id&#x27;)+&#x27;-&gt;&#x27;+it.group(&#x27;name&#x27;), end=&#x27;\t&#x27;)</span><br><span class="line">        dic = it.groupdict()</span><br><span class="line">        dic[&#x27;id&#x27;] = it.group(&#x27;id&#x27;).strip()</span><br><span class="line">        dic[&#x27;name&#x27;] = it.group(&#x27;name&#x27;).strip()</span><br><span class="line">        csvwriter.writerow(dic.values())</span><br><span class="line">f.close()</span><br><span class="line">print(&#x27;over!&#x27;)</span><br></pre></td></tr></table></figure>

<p>总结：</p>
<ul>
<li>每一页是一个url，需要找规律然后遍历所有url，才能爬到所有的页码</li>
<li>正则可以多找一点然后中间不重要的就 <code>.*?</code> (换行符之类的不清楚的也这样)</li>
<li>加入文件读写要注意！ <a target="_blank" rel="noopener" href="https://blog.csdn.net/album_gyd/article/details/89630708">https://blog.csdn.net/album_gyd&#x2F;article&#x2F;details&#x2F;89630708</a> 相关博客</li>
<li><strong>注意注意，每一次循环都是从当前文件追加内容，mode是a不是w</strong></li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/p5ych2022/IHS@master/img/image-20230108222632061-1024x127.png"></p>
<h6 id="爬取电影天堂信息"><a href="#爬取电影天堂信息" class="headerlink" title="爬取电影天堂信息"></a>爬取电影天堂信息</h6><p>思路：在主页中找到目标电影-&gt;进入其子页面-&gt;拿到子页面里面的电影名下载链接等信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line">import urllib3</span><br><span class="line"></span><br><span class="line">urllib3.disable_warnings()</span><br><span class="line">url0 = &#x27;https://www.dytt89.com/&#x27;</span><br><span class="line">headers = &#123;</span><br><span class="line">    &#x27;Cookie&#x27;:&#x27;Hm_lvt_93b4a7c2e07353c3853ac17a86d4c8a4=1673189156; Hm_lpvt_93b4a7c2e07353c3853ac17a86d4c8a4=1673189156; Hm_lvt_8e745928b4c636da693d2c43470f5413=1673189156; Hm_lpvt_8e745928b4c636da693d2c43470f5413=1673189156; Hm_lvt_0113b461c3b631f7a568630be1134d3d=1673189156; Hm_lpvt_0113b461c3b631f7a568630be1134d3d=1673189156&#x27;,</span><br><span class="line">    &#x27;User-Agent&#x27;:&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:108.0) Gecko/20100101 Firefox/108.0&#x27;</span><br><span class="line">&#125;</span><br><span class="line">resp0 = requests.get(url0, headers=headers, verify=False)  #去掉安全验证</span><br><span class="line">s0 = resp0.content.decode(&#x27;gbk&#x27;)</span><br><span class="line"></span><br><span class="line">&#x27;&#x27;&#x27;&lt;div class=&quot;co_area2&quot; style=&quot;float:left;width:470px;height:auto;overflow:hidden;margin-left:6px;&quot;&gt;</span><br><span class="line">                &lt;div class=&quot;title_all&quot;&gt;&lt;p&gt;&lt;span style=&quot;float:left;&quot;&gt;2023必看热片&lt;/span&gt;&lt;em style=&quot;float:right;&quot;&gt;&lt;a href=&quot;/html/bikan/&quot;&gt;更多&gt;&gt;&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;</span><br><span class="line">                &lt;div class=&quot;co_content222&quot;&gt;</span><br><span class="line">                    &lt;ul&gt;</span><br><span class="line">                        &lt;li&gt;&lt;a href=&#x27;/i/106759.html&#x27; title=&quot;2022年国产冒险灾难片《搜救》HD国语中字&quot;&gt;2022年国产冒险灾难片《搜救》HD国语中字&lt;/a&gt;&lt;span&gt;&lt;font color=#FF0000&gt;11-06&lt;/font&gt;&lt;/span&gt;&lt;/li&gt;</span><br><span class="line">&lt;li&gt;&lt;a href=&#x27;/i/105464.html&#x27; title=&quot;2022年美国动作犯罪片《亡命救护车》蓝光中英双字&quot;&gt;2022年美国动作犯罪片《亡命救护车》蓝光中英双字&lt;/a&gt;&lt;span&gt;&lt;font color=#FF0000&gt;11-03&lt;/font&gt;&lt;/span&gt;&lt;/li&gt;&#x27;&#x27;&#x27;</span><br><span class="line"></span><br><span class="line">#这个一次查询出来很困难，因为要掐头去尾，所以选择筛选两次！</span><br><span class="line">obj0 = re.compile(r&#x27;&lt;div class=&quot;co_area2&quot; .*?2023必看热片&lt;/span&gt;.*?&lt;ul&gt;(?P&lt;s1&gt;.*?&lt;/ul&gt;)&#x27;, re.S)</span><br><span class="line">s1 = obj0.findall(s0)</span><br><span class="line">#print(type(s1))     #list</span><br><span class="line">#print(type(&#x27;&#x27;.join(s1).strip())) #str</span><br><span class="line">s2 = &#x27;&#x27;.join(s1).strip()</span><br><span class="line">obj1 = re.compile(r&quot;&lt;li&gt;&lt;a href=&#x27;(?P&lt;url&gt;.*?)&#x27; title=.*?&lt;/font&gt;&lt;/span&gt;&lt;/li&gt;&quot;, re.S)</span><br><span class="line">result1 = obj1.finditer(s2)</span><br><span class="line">for it in result1:</span><br><span class="line">    x = it.group(&#x27;url&#x27;)</span><br><span class="line">    url1 = url0+x</span><br><span class="line">    #print(url1)</span><br><span class="line">    headers = &#123;</span><br><span class="line">      &#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:108.0) Gecko/20100101 Firefox/108.0&#x27;</span><br><span class="line">    &#125;</span><br><span class="line">    resp1 = requests.get(url1, headers=headers, verify=False)</span><br><span class="line">    s3 = resp1.content.decode(&#x27;gbk&#x27;)</span><br><span class="line">    obj2 = re.compile(r&#x27;片　　名(?P&lt;name&gt;.*?)&lt;br /&gt;.*?&lt;li&gt;&lt;a href=&quot;(?P&lt;href&gt;.*?)&quot;&gt;.*?&lt;/a&gt;&lt;/li&gt;&#x27;, re.S)</span><br><span class="line">    result3 = obj2.finditer(s3)</span><br><span class="line">    for it in result3:</span><br><span class="line">        print(it.group(&#x27;name&#x27;)+&#x27;-&gt;&#x27;+it.group(&#x27;href&#x27;))</span><br></pre></td></tr></table></figure>

<ul>
<li>报错<code>Adding certificate verification is strongly advised</code>，需要：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import urllib3</span><br><span class="line">urllib3.disable_warnings()</span><br></pre></td></tr></table></figure>

<ul>
<li>一次筛选做不出来的就筛选两次！</li>
</ul>
<h4 id="bs4解析"><a href="#bs4解析" class="headerlink" title="bs4解析"></a>bs4解析</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;!--结构--&gt;</span><br><span class="line">&lt;标签 属性=属性值&gt;被标记的内容&lt;/标签&gt;</span><br><span class="line">&lt;!--</span><br><span class="line">bs4就是通过标签和属性来定位内容</span><br><span class="line">--&gt;</span><br></pre></td></tr></table></figure>

<p>bs4也需要安装： <code>pip install bs4</code></p>
<h5 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h5><h6 id="北京新发地爬取菜价"><a href="#北京新发地爬取菜价" class="headerlink" title="北京新发地爬取菜价"></a>北京新发地爬取菜价</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">import csv</span><br><span class="line"></span><br><span class="line">url = &#x27;http://www.xinfadi.com.cn/index.html&#x27;</span><br><span class="line">resp = requests.get(url)</span><br><span class="line"></span><br><span class="line">f = open(&#x27;菜价.csv&#x27;,mode = &#x27;w&#x27;)</span><br><span class="line">csvwriter = csv.writer(f)</span><br><span class="line"></span><br><span class="line">#解析数据</span><br><span class="line"># 1.把页面源代码交给BeautifulSoup进行处理，生成bs对象</span><br><span class="line">page = BeautifulSoup(resp.text, &#x27;html.parser&#x27;) # 指定html解释器</span><br><span class="line"># 2.从bs对象中查找数据</span><br><span class="line"># find(标签， 属性=值)</span><br><span class="line"># find_all(标签， 属性=值)</span><br><span class="line"></span><br><span class="line"># table = page.find(&#x27;table&#x27;, class_ = &#x27;hp_table&#x27;)  #class是python的关键字，不能直接写class需要加一个 _</span><br><span class="line">table = page.find(&#x27;table&#x27;, attrs=&#123;&#x27;class&#x27;: &#x27;hp_table&#x27;&#125;)        #这样写也可以，就避免用class报错了</span><br><span class="line">#拿到所有数据行</span><br><span class="line">trs = table.find_all(&#x27;tr&#x27;)[1:]</span><br><span class="line">for tr in trs:  #每一行</span><br><span class="line">    tds = tr.find_all(&#x27;td&#x27;) #拿到行中的所有td</span><br><span class="line">    &#x27;name&#x27; = tds[0].text   # .text表示拿到被标签标记的内容</span><br><span class="line">    &#x27;low&#x27; = tds[1].text</span><br><span class="line">    &#x27;avg&#x27; = tds[2].text</span><br><span class="line">    &#x27;high&#x27; = tds[3].text</span><br><span class="line">    &#x27;gui&#x27; = tds[4].text</span><br><span class="line">    &#x27;kind&#x27; = tds[5].text</span><br><span class="line">    &#x27;date&#x27; = tds[6].text</span><br><span class="line">    csvwriter.writerow([name,low,avg,high,gui,kind,date])</span><br><span class="line">    f.close()</span><br><span class="line">    print(&#x27;over!&#x27;)</span><br></pre></td></tr></table></figure>

<h6 id="优美美图库图片"><a href="#优美美图库图片" class="headerlink" title="优美美图库图片"></a>优美美图库图片</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">#爬取唯美图片</span><br><span class="line">#拿到主页面源码</span><br><span class="line">#提取到页面的图片链接 src</span><br><span class="line"></span><br><span class="line">import requests</span><br><span class="line">from bs4 import BeautifulSoup</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">url = &#x27;http://www.umeituku.com/weimeitupian/&#x27;</span><br><span class="line">resp = requests.get(url)</span><br><span class="line">page0 = BeautifulSoup(resp.content.decode(&#x27;utf-8&#x27;), &#x27;html.parser&#x27;)</span><br><span class="line">ul = page0.find(&#x27;div&#x27;, class_=&quot;TypeList&quot;)</span><br><span class="line"># print(ul)</span><br><span class="line">#找到所有的a标签</span><br><span class="line">imgs = ul.find_all(&#x27;img&#x27;)</span><br><span class="line"># print(imgs)</span><br><span class="line"># 找到所有的的src</span><br><span class="line">for img in imgs:</span><br><span class="line">    src = img.get(&#x27;src&#x27;)</span><br><span class="line">    # 下载图片</span><br><span class="line">    img_resp = requests.get(src)</span><br><span class="line">    txt = img_resp.content       #content是文件内容，也就是图片的所有字节，保存在一个文件里面就是图片了</span><br><span class="line">    img_name = src.split(&#x27;/&#x27;)[-1]  #用图片地址最后几位作为图片名</span><br><span class="line">    with open(&#x27;唯美图片/&#x27;+img_name, mode=&#x27;wb&#x27;) as f:</span><br><span class="line">        f.write(txt)               #图片内容写入文件中</span><br><span class="line">    print(&#x27;over&#x27;+img_name)</span><br><span class="line">    time.sleep(0.5)</span><br><span class="line">print(&#x27;over!&#x27;)</span><br></pre></td></tr></table></figure>

<h4 id="xpath解析"><a href="#xpath解析" class="headerlink" title="xpath解析"></a>xpath解析</h4><p>Xpath是在XML文档中搜索内容的一门语言</p>
<p>html是xml的一个子集</p>
<p>需要安装 lxml模块 <code>pip install lxml</code></p>
<h6 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"># xpath_1</span><br><span class="line">from lxml import etree</span><br><span class="line">xml = &#x27;&#x27;&#x27;</span><br><span class="line">&lt;book&gt;</span><br><span class="line">    &lt;id&gt;1&lt;/id&gt;</span><br><span class="line">    &lt;name&gt;野花遍地香&lt;/name&gt;</span><br><span class="line">    &lt;price&gt;1.23&lt;/price&gt;</span><br><span class="line">    &lt;nick&gt;臭豆腐&lt;/nick&gt;</span><br><span class="line">    &lt;author&gt;</span><br><span class="line">        &lt;nick id = &#x27;10086&#x27;&gt;周大强&lt;/nick&gt;</span><br><span class="line">        &lt;nick id = &#x27;10010&#x27;&gt;周芷若&lt;/nick&gt;</span><br><span class="line">        &lt;nick class = &#x27;joy&#x27;&gt;周杰伦&lt;/nick&gt;</span><br><span class="line">        &lt;nick class = &#x27;jolin&#x27;&gt;蔡依林&lt;/nick&gt;</span><br><span class="line">        &lt;div&gt;</span><br><span class="line">            &lt;nick&gt;热热热热1&lt;/nick&gt;</span><br><span class="line">        &lt;/div&gt;</span><br><span class="line">        &lt;span&gt;</span><br><span class="line">            &lt;nick&gt;热热热热2&lt;/nick&gt;</span><br><span class="line">        &lt;/span&gt;</span><br><span class="line">    &lt;/author&gt;</span><br><span class="line"></span><br><span class="line">    &lt;partner&gt;</span><br><span class="line">        &lt;nick id=&#x27;ppc&#x27;&gt;胖胖陈&lt;/nick&gt;</span><br><span class="line">        &lt;nick id=&#x27;ppbc&#x27;&gt;胖胖不陈&lt;/nick&gt;</span><br><span class="line">    &lt;/partner&gt;  </span><br><span class="line">&lt;/book&gt;    </span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">tree = etree.XML(xml)</span><br><span class="line">#result = tree.xpath(&quot;/book/name/text()&quot;) # / 表示层级关系，第一个/是根节点  ,text()表示拿节点后面的东西</span><br><span class="line"></span><br><span class="line">print(tree.xpath(&quot;/book/name/text()&quot;)) # [&#x27;野花遍地香&#x27;]</span><br><span class="line"></span><br><span class="line"># // 表示该级以及后代的nick都要</span><br><span class="line">print(tree.xpath(&quot;/book/author//nick/text()&quot;)) #[&#x27;周大强&#x27;, &#x27;周芷若&#x27;, &#x27;周杰伦&#x27;, &#x27;蔡依林&#x27;, &#x27;热热热热&#x27;]</span><br><span class="line"></span><br><span class="line"># * 通配符</span><br><span class="line">print(tree.xpath(&quot;/book/author/*/nick/text()&quot;))  # * 可以代表任意的标签</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># xpath_2</span><br><span class="line">from lxml import etree</span><br><span class="line">tree = etree.parse(&quot;b.html&quot;)</span><br><span class="line"></span><br><span class="line"># xpath顺序是从1开始的，li[1]指的是第一个li也就是百度</span><br><span class="line">result = tree.xpath(&#x27;/html/body/ul/li[1]/a/text()&#x27;)</span><br><span class="line">#  [@href=&#x27;dapao&#x27;]  跟bs4很像</span><br><span class="line">result = tree.xpath(&#x27;/html/body/ol/li/a[@href=&quot;dapao&quot;]/text()&#x27;)</span><br><span class="line">print(result)</span><br><span class="line"></span><br><span class="line"># 相对查找</span><br><span class="line">ol_li_list = tree.xpath(&#x27;/html/body/ol/li&#x27;)</span><br><span class="line">for li in ol_li_list:</span><br><span class="line">    result = li.xpath(&#x27;./a/text()&#x27;)  # ./相对查找</span><br><span class="line">    result1 = li.xpath(&#x27;./a/@href&#x27;)   # @表示属性</span><br><span class="line">    print(result1)</span><br><span class="line">    print(result)</span><br></pre></td></tr></table></figure>

<h6 id="实战"><a href="#实战" class="headerlink" title="实战"></a>实战</h6><p>抓取猪八戒网站信息</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">#xpath_实战_猪八戒网</span><br><span class="line">import requests</span><br><span class="line">from lxml import etree</span><br><span class="line"></span><br><span class="line">url = &#x27;https://beijing.zbj.com/search/service/?kw=saas&amp;r=2&#x27;</span><br><span class="line">resp = requests.get(url)</span><br><span class="line"># ans = &quot;&quot;.join(str(resp.text.encode()).split())</span><br><span class="line"># resps = ans.encode().decode()</span><br><span class="line"></span><br><span class="line">html = etree.HTML(resp.text)</span><br><span class="line">divs = html.xpath(&#x27;/html/body/div[2]/div/div/div[3]/div/div[4]/div[4]/div[1]/div&#x27;)</span><br><span class="line"># print(divs)</span><br><span class="line">for div in divs:</span><br><span class="line">    print(div.xpath(&quot;./div/div[3]/div[1]/span/text()&quot;))</span><br></pre></td></tr></table></figure>

<ul>
<li>主要就是绝对路径和相对路径写对</li>
</ul>
<h2 id="Requests-进阶"><a href="#Requests-进阶" class="headerlink" title="Requests 进阶"></a>Requests 进阶</h2><h3 id="处理cookie"><a href="#处理cookie" class="headerlink" title="处理cookie"></a>处理cookie</h3><p>登录小说网流程：</p>
<p>登录 -&gt; 得到cookie</p>
<p>带着cookie 去请求到书架的url -&gt; 获得书架上的内容</p>
<ul>
<li>必须把上面两个操作连起来</li>
<li>我们可以用session请求 -&gt; session可以认为是一连串请求，在这个过程中cookie不会丢失</li>
</ul>
<p>例：处理cookie登录小说网</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#处理cookie登录cookie</span><br><span class="line">import requests</span><br><span class="line">#会话</span><br><span class="line">session = requests.session()</span><br><span class="line">data = &#123;</span><br><span class="line">        &#x27;loginNAme&#x27;: &#x27;18782910550&#x27;,</span><br><span class="line">        &#x27;password&#x27;: &#x27;123youzhi&#x27;</span><br><span class="line">&#125;</span><br><span class="line">#1.登录</span><br><span class="line">url = &#x27;https://user.17k.com/ck/user/login&#x27;</span><br><span class="line">resp = session.post(url, data=data)</span><br><span class="line"># print(resp.cookies)</span><br><span class="line">#拿书架上的书   用session不用requests，session是有记忆的</span><br><span class="line">resp1 = session.get(&#x27;找到的有用的url&#x27;)</span><br><span class="line">print(resp1.json())</span><br></pre></td></tr></table></figure>

<ul>
<li>seesion 本质上是第一次请求拿到cookie之后，把cookie保存下来，第二次请求的时候直接用第一次的cookie请求了</li>
<li>如果还是用requests也是可以的，只用手动加上从浏览器复制过来的cookie就可以了</li>
</ul>
<h3 id="防盗链"><a href="#防盗链" class="headerlink" title="防盗链"></a>防盗链</h3><p>开发者工具（F12）看到的代码是页面实时的真实代码，而页面源代码则不是最终的代码，而是还需要经过二次渲染的</p>
<h5 id="盗链"><a href="#盗链" class="headerlink" title="盗链"></a>盗链</h5><blockquote>
<p>盗链是指在自己的页面上展示一些并不在自己服务器上的一些内容， 获取别人的资源地址，绕过别人的资源展示页面，直接在自己的页面上向最终用户提供此内容。 一般被盗链的都是图片、 音乐、视频、软件等资源。通过盗链的手段可以减轻自己服务器的负担</p>
</blockquote>
<h5 id="防盗链的工作原理"><a href="#防盗链的工作原理" class="headerlink" title="防盗链的工作原理"></a><strong>防盗链的工作原理</strong></h5><blockquote>
<p>通过Refer或者签名，网站可以检测目标网页访问的来源网页，如果是资源文件，则可以追踪到显示他的网页地址 一旦检测到来源不是本站，即进行阻止或者返回指定的页面</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"># 1.拿到contID</span><br><span class="line"># 2.拿到videoStatus返回的json  -&gt; srcURL</span><br><span class="line"># 3.把srcURL里面的内容进行调整</span><br><span class="line"># 4.合成真实的视频地址，下载视频</span><br><span class="line">import requests</span><br><span class="line"></span><br><span class="line">url = &#x27;https://www.pearvideo.com/video_1748549&#x27;</span><br><span class="line">contID = url.split(&#x27;_&#x27;)[-1]</span><br><span class="line">vedioStatusURL = &#x27;https://www.pearvideo.com/videoStatus.jsp?contId=1748549&amp;mrd=0.09049480874281857&#x27;</span><br><span class="line">headers = &#123;</span><br><span class="line">    &#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:108.0) Gecko/20100101 Firefox/108.0&#x27;,</span><br><span class="line">    # 防盗链:Referer(该请求的上一级)  必须合理</span><br><span class="line">    &#x27;Referer&#x27;: url</span><br><span class="line">&#125;</span><br><span class="line">resp = requests.get(vedioStatusURL,headers=headers)</span><br><span class="line">dic = resp.json()</span><br><span class="line">srcURL = dic[&#x27;videoInfo&#x27;][&#x27;videos&#x27;][&#x27;srcUrl&#x27;]</span><br><span class="line">systemTime = dic[&#x27;systemTime&#x27;]</span><br><span class="line">srcURL1 = srcURL.replace(systemTime, &#x27;cont-&#x27;+contID)</span><br><span class="line"># print(srcURL1)</span><br><span class="line"># 下载链接</span><br><span class="line">with open(&#x27;vedio/&#x27;+contID+&#x27;.mp4&#x27;, mode=&#x27;wb&#x27;) as f:       #要加后缀！</span><br><span class="line">    f.write(requests.get(srcURL1).content)</span><br><span class="line">f.close()</span><br><span class="line">print(&#x27;over!&#x27;)</span><br></pre></td></tr></table></figure>

<h3 id="代理"><a href="#代理" class="headerlink" title="代理"></a>代理</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">proxies = &#123;</span><br><span class="line">    &#x27;https&#x27;: &#x27;https://193.134.211.196:21609&#x27;     #代理ip要自己去找</span><br><span class="line">&#125;</span><br><span class="line">resp = requests.get(&#x27;https://www.baidu.com&#x27;, proxies=proxies)</span><br><span class="line">resp.encoding = &#x27;utf-8&#x27;</span><br><span class="line">print(resp.text)</span><br></pre></td></tr></table></figure>

<h3 id="综合训练（wyy）"><a href="#综合训练（wyy）" class="headerlink" title="综合训练（wyy）"></a>综合训练（wyy）</h3><h5 id="爬取网易云热评"><a href="#爬取网易云热评" class="headerlink" title="爬取网易云热评"></a>爬取网易云热评</h5><ul>
<li>找到热评：</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/p5ych2022/IHS@master/img/image-20230110232047495-1024x438.png" style="zoom:67%;" />

<ul>
<li>找到未加密的参数-&gt;想办法把参数加密(用网易的加密方式) 【params，encSecKey】-&gt;请求网易拿到数据 解密 开发者工具 -&gt; 栈跟踪[找到网页渲染调用的(js)脚本，里面就有加密方式之类的]</li>
<li>点击栈跟踪，找到最上面的哪一个js脚本打开</li>
<li>默认会在最后send的代码也就是最后执行的代码那一行有高亮，打一个断点进行刷新调试</li>
<li>找到我们目标XHR的网页，发现此时params等信息已经被加密</li>
<li>就继续栈跟踪，找在改脚本执行之前的脚本里面找。直到找到params没有被加密的地方到已经加密的地方。这中间就实现了key的加密</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/p5ych2022/IHS@master/img/image-20230111001434047-1024x829.png" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/p5ych2022/IHS@master/img/image-20230111001456613-1024x664.png" style="zoom:67%;" />

<ul>
<li>上面两张图就说明就是be3x这里实现的加密</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/p5ych2022/IHS@master/img/image-20230111001952355.png" style="zoom:67%;" />

<ul>
<li>i3x 的rid和ThreadID -》e3x的data 找到加密前的东西：</li>
</ul>
<img src="https://cdn.jsdelivr.net/gh/p5ych2022/IHS@master/img/image-20230111004110413.png" style="zoom:67%;" />

<ul>
<li>找加密方式 （dd）</li>
</ul>
<h2 id="提高爬虫效率"><a href="#提高爬虫效率" class="headerlink" title="提高爬虫效率"></a>提高爬虫效率</h2><p>选择多线程，多进程，协程等操作来完成异步爬虫</p>
<p><strong>概念辨析</strong></p>
<blockquote>
<p>一个在内存中运行的应用程序。每个进程都有自己独立的一块内存空间，一个进程可以有多个线程，比如在Windows系统中，一个运行的xx.exe就是一个<strong>进程</strong>。</p>
<p>进程中的一个执行任务（控制单元），负责当前进程中程序的执行。一个进程至少有一个线程，一个进程可以运行多个线程，多个<strong>线程</strong>可共享数据。</p>
</blockquote>
<p>线程：执行单位，程序运行的时候有一个主线程</p>
<p>进程：资源单位，每一个进程至少有一个线程</p>
<h4 id="多线程"><a href="#多线程" class="headerlink" title="多线程"></a>多线程</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">#先看看单线程</span><br><span class="line">def func():</span><br><span class="line">    for i in range(1000):</span><br><span class="line">        print(&quot;func&quot;, i)</span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    func()</span><br><span class="line">    for i in range(1000):</span><br><span class="line">        print(&quot;main&quot;, i)</span><br><span class="line"></span><br><span class="line">#  多线程  第一种写法</span><br><span class="line">from threading import Thread  #线程类</span><br><span class="line">def func():</span><br><span class="line">    for i in range(1000):</span><br><span class="line">        print(&quot;func&quot;, i)</span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    t = Thread(target=func) #创建线程，并告诉新的线程，它负责的是 func</span><br><span class="line">    t.start()   #多线程状态为可以开始工作的状态，但是具体的执行时间由CPU决定</span><br><span class="line">    for i in range(1000):</span><br><span class="line">        print(&quot;main&quot;, i)</span><br><span class="line"># 打印结果有些时候会出现两个一起打印了，‘mainfunc 27’</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#  多线程  第二种写法</span><br><span class="line">from threading import Thread </span><br><span class="line">class MyThread(Thread):</span><br><span class="line">    def run(self):  #固定写法</span><br><span class="line">        for i in range(1000):</span><br><span class="line">            print(&quot;子线程&quot;, i)</span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    t = MyThread()</span><br><span class="line">    # t.run()   #不行？这样就是方法的调用了，就变成单线程了</span><br><span class="line">    t.start()</span><br><span class="line"></span><br><span class="line">    for i in range(1000):</span><br><span class="line">        print(&quot;主线程&quot;, i)</span><br></pre></td></tr></table></figure>

<h4 id="多进程"><a href="#多进程" class="headerlink" title="多进程"></a>多进程</h4><p>一般情况下开辟多进程会比较浪费资源，不建议使用。只用稍微了解一下就可以 写法基本上和线程一样的！</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from multiprocessing import Process</span><br><span class="line"></span><br><span class="line">def func():</span><br><span class="line">    for i in range(1000):</span><br><span class="line">        print(&quot;子进程&quot;, i)</span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    p = Process(target=func)</span><br><span class="line">    p.start()</span><br><span class="line">    for i in range(1000):</span><br><span class="line">        print(&quot;主进程&quot;, i)</span><br></pre></td></tr></table></figure>

<h4 id="线程池和进程池"><a href="#线程池和进程池" class="headerlink" title="线程池和进程池"></a>线程池和进程池</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 线程池:一次性开辟一些线程，用户直接给线程池提交任务</span><br><span class="line"># 线程任务的调度交给线程池来完成</span><br><span class="line"></span><br><span class="line">from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor</span><br><span class="line"></span><br><span class="line">def fn(name):</span><br><span class="line">    for i in range(1000):</span><br><span class="line">        print(name, i)</span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    #创建线程池</span><br><span class="line">    with ThreadPoolExecutor(20) as t:</span><br><span class="line">        for i in range(100):</span><br><span class="line">            t.submit(fn, name=f&#x27;线程&#123;i&#125;&#x27;)</span><br><span class="line">    # 外面的程序会等待线程池中的任务全部执行完毕，才能继续执行</span><br><span class="line">    print(&#x27;123&#x27;)</span><br><span class="line"></span><br><span class="line"># 线程94991线程96 993 &lt;- 会出现这样的数据</span><br></pre></td></tr></table></figure>

<h4 id="协程"><a href="#协程" class="headerlink" title="协程"></a>协程</h4><h6 id="阻塞状态"><a href="#阻塞状态" class="headerlink" title="阻塞状态"></a>阻塞状态</h6><ul>
<li>当程序处于阻塞状态的时候，CPU是不为我工作的</li>
<li><code>input()</code>，程序也是处于阻塞状态</li>
<li>一般情况下，当程序处于IO(input &amp; output)操作的时候，线程都会处于阻塞状态</li>
</ul>
<h6 id="协程-1"><a href="#协程-1" class="headerlink" title="协程"></a>协程</h6><p>当程序遇见IO操作的时候，可以选择性的切换到其他任务上</p>
<p>协程， 我们又称为<strong>微线程</strong>，协程它不像线程和进程那样，需要进行系统内核上的上下文切换，协程的上下文切换是由开发人员决定的。</p>
<blockquote>
<p>协程运行在线程之上，当一个协程执行完成后，可以选择主动让出，让另一个协程运行在当前线程之上。<strong>协程并没有增加线程数量，只是在线程的基础之上通过分时复用的方式运行多个协程</strong></p>
</blockquote>
<ul>
<li>在微观上，是一个任务一个任务进行切换，切换条件一般就是IO操作</li>
<li>宏观上，我们能看到的其实是多个任务在一起执行</li>
<li>也就是，多任务异步操作</li>
<li>注意上面这一切都是：在单线程的条件下</li>
</ul>
<h6 id="多任务异步协程"><a href="#多任务异步协程" class="headerlink" title="多任务异步协程"></a>多任务异步协程</h6><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line"># 先看看无协程</span><br><span class="line">import asyncio</span><br><span class="line"></span><br><span class="line">async def func():</span><br><span class="line">    print(&#x27;你好&#x27;)</span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    g = func()  #此时的函数是异步协程函数，函数执行得到的是一个协程对象</span><br><span class="line">    asyncio.run(g)      #协程程序需要asyncio模块的支持</span><br><span class="line"></span><br><span class="line">#协程处理多个任务</span><br><span class="line">import asyncio</span><br><span class="line">import time</span><br><span class="line"></span><br><span class="line">async def func1():</span><br><span class="line">    print(&#x27;你好1&#x27;)</span><br><span class="line">    # time.sleep(3) #当程序出现了同步操作的时候，异步就中断了</span><br><span class="line">    await asyncio.sleep(3) #这是异步操作的sleep</span><br><span class="line">    print(&#x27;你好1&#x27;)</span><br><span class="line"></span><br><span class="line">async def func2():</span><br><span class="line">    print(&#x27;你好2&#x27;)</span><br><span class="line">    # time.sleep(3)</span><br><span class="line">    await asyncio.sleep(3)</span><br><span class="line">    print(&#x27;你好2&#x27;)</span><br><span class="line"></span><br><span class="line">async def func3():</span><br><span class="line">    print(&#x27;你好3&#x27;)</span><br><span class="line">    # time.sleep(3)</span><br><span class="line">    await asyncio.sleep(3)</span><br><span class="line">    print(&#x27;你好3&#x27;)</span><br><span class="line"></span><br><span class="line">async def func4():</span><br><span class="line">    print(&#x27;你好4&#x27;)</span><br><span class="line">    # time.sleep(3)</span><br><span class="line">    await asyncio.sleep(3)</span><br><span class="line">    print(&#x27;你好4&#x27;)</span><br><span class="line"></span><br><span class="line">async def func5():</span><br><span class="line">    print(&#x27;你好5&#x27;)</span><br><span class="line">    # time.sleep(3)</span><br><span class="line">    await asyncio.sleep(3)</span><br><span class="line">    print(&#x27;你好5&#x27;)</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;不推荐这种写法，最好有一个协程对象[main函数]&quot;&quot;&quot;</span><br><span class="line"># if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">#     f1 = func1()</span><br><span class="line">#     f2 = func2()</span><br><span class="line">#     f3 = func3()</span><br><span class="line">#     f4 = func4()</span><br><span class="line">#     f5 = func5()</span><br><span class="line">#     tasks = [f1, f2, f3, f4, f5]</span><br><span class="line">#     t1 = time.time()</span><br><span class="line">#     # 一次性启动多个任务(协程)</span><br><span class="line">#     asyncio.run(asyncio.wait(tasks))</span><br><span class="line">#     t2 = time.time()</span><br><span class="line">#     print(t2-t1)</span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;推荐写法: &quot;&quot;&quot;</span><br><span class="line">async def main():</span><br><span class="line">    # 第一种写法(不推荐)</span><br><span class="line">    # f1 = fun1()</span><br><span class="line">    # await f1</span><br><span class="line"></span><br><span class="line">    # 第二种写法(推荐)</span><br><span class="line">    tasks = [func1(),</span><br><span class="line">             func2(),</span><br><span class="line">             func3(),</span><br><span class="line">             func4(),</span><br><span class="line">             func5()</span><br><span class="line">    ]</span><br><span class="line">    await asyncio.wait(tasks)</span><br><span class="line"></span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    t1 = time.time()</span><br><span class="line">    #一次性启动多个任务(协程)</span><br><span class="line">    asyncio.run(main())</span><br><span class="line">    t2 = time.time()</span><br><span class="line">    print(t2-t1)</span><br></pre></td></tr></table></figure>

<h4 id="异步http请求aiohttp模块"><a href="#异步http请求aiohttp模块" class="headerlink" title="异步http请求aiohttp模块"></a>异步http请求<strong>aiohttp</strong>模块</h4><ul>
<li>requests.get()是同步的代码 -&gt; 想办法变成异步的 -&gt; 异步操作aiohttp</li>
</ul>
<p>这个模块也需要安装 <code>pip install aiohttp</code></p>
<p>e.g:简单的aiohttp代替requests模块【结合协程】</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">import asyncio</span><br><span class="line">import aiohttp</span><br><span class="line"></span><br><span class="line">urls = [</span><br><span class="line">    &#x27;https://i1.huishahe.com/uploads/tu/201911/9999/6c7b9884f3.png&#x27;,</span><br><span class="line">    &#x27;https://i1.huishahe.com/uploads/tu/201911/9999/93535131da.png&#x27;,</span><br><span class="line">    &#x27;https://i1.huishahe.com/uploads/tu/201908/9999/ffaaacbfad.jpeg&#x27;</span><br><span class="line">]</span><br><span class="line">async def aiodownload(url):</span><br><span class="line">    name = url.rsplit(&#x27;/&#x27;, 1)[1]</span><br><span class="line">    async with aiohttp.ClientSession() as session:</span><br><span class="line">        async with session.get(url) as resp:</span><br><span class="line">            with open(&#x27;真的很美/&#x27;+name, mode=&#x27;wb&#x27;) as f:</span><br><span class="line">                f.write(await resp.content.read())  #读取内容是异步的，需要await挂起</span><br><span class="line">async def main():</span><br><span class="line">    tasks = []</span><br><span class="line">    for url in urls:</span><br><span class="line">        tasks.append(aiodownload(url))</span><br><span class="line">    await asyncio.wait(tasks)</span><br><span class="line">if __name__ == &#x27;__main__&#x27;:</span><br><span class="line">    asyncio.run(main())</span><br></pre></td></tr></table></figure>

<h5 id="抓取百度小说-dd"><a href="#抓取百度小说-dd" class="headerlink" title="抓取百度小说(dd)"></a>抓取百度小说(dd)</h5><h5 id="抓取视频网站-dd"><a href="#抓取视频网站-dd" class="headerlink" title="抓取视频网站(dd)"></a>抓取视频网站(dd)</h5><p>一般视频网站怎么处理视频？</p>
<blockquote>
<p>用户上传 -&gt; 转码(把视频做处理，2k, 1080p, 标清)</p>
<p>-&gt; 切片处理(把单个文件拆分) -&gt; 用户拉进度条时前面的文件不用加载</p>
<p>需要一个文件记录：1.视频播放顺序 2.视频存放的路径</p>
</blockquote>
<h2 id="selenium"><a href="#selenium" class="headerlink" title="_selenium"></a>_selenium</h2><blockquote>
<p>有些程序是加密的，我们自己解密拿数据的话会非常痛苦，然而这些程序代码返回给浏览器之后是可以直接渲染成我们想要的东西的。所以衍生一个问题 -&gt; 能不能让我们的程序直接连接到服务器，然后让服务器帮我们解密了我们拿最后的数据？</p>
<p>selenium本来是自动化测试工具，作用就是打开一个浏览器然后像人一样去操作浏览器，所以程序员可以从selenium中直接提取网页上的各种信息</p>
</blockquote>
<ul>
<li>也需要安装 pip install selenium</li>
<li>还需要下载浏览器驱动（注意版本最好跟自己的浏览器一样）</li>
<li>把解压的浏览器驱动放在python解释器所在的文件夹里面</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 让selenium启动火狐浏览器  注意版本一定要对，否则会不兼容报错</span><br><span class="line">from selenium.webdriver import Firefox</span><br><span class="line"># 1.创建浏览器对象</span><br><span class="line">web = Firefox()</span><br><span class="line"># 2.打开一个网址</span><br><span class="line">web.get(&#x27;http://www.baidu.com&#x27;)</span><br><span class="line">print(web.title)</span><br><span class="line">web.close()</span><br></pre></td></tr></table></figure>

<p>e.g:抓拉钩</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">from selenium.webdriver import Firefox</span><br><span class="line">from selenium.webdriver.common.keys import Keys</span><br><span class="line">from selenium.webdriver.common.by import By</span><br><span class="line"></span><br><span class="line">web = Firefox()</span><br><span class="line">web.get(&#x27;http://lagou.com&#x27;)</span><br><span class="line"># 模拟点击事件</span><br><span class="line"># 元素定位  xpath</span><br><span class="line">element = web.find_element(By.XPATH, r&#x27;/html/body/div[10]/div[1]/div[2]/div[2]/div[1]/div/ul/li[1]/a&#x27;)</span><br><span class="line">element.click()     #点击目标元素，模拟用户操作</span><br><span class="line"></span><br><span class="line"># 注意这个点击之后浏览器会刷新，会需要时间，如果后面程序执行时间小于刷新时间极有可能会报错，所以我们最好加上sleep</span><br><span class="line"># time.sleep(1)    要先 import time</span><br><span class="line"></span><br><span class="line"># 模拟搜索事件</span><br><span class="line"># 找到输入框 xpath</span><br><span class="line">search = web.find_element(By.XPATH, r&#x27;//*[@id=&quot;search_input&quot;]&#x27;)</span><br><span class="line"># 输入python  =》点击搜索或者输入回车</span><br><span class="line">search.send_keys(&quot;python&quot;, Keys.ENTER)</span><br><span class="line"></span><br><span class="line"># 利用xpath拿数据。。。  就可以拿到源代码里面没有的东西，直接前端html拿</span><br><span class="line">table =  web.find_element(By.XPATH, r&#x27;//*[@id=&quot;TableList&quot;]/table&#x27;)</span><br><span class="line">print(table.text)</span><br></pre></td></tr></table></figure>

<p>e.g： 切换窗口</p>
<p><code>web.switch_to.window(web.window_handles[-1]) # window_handles就是浏览器上面那个窗口</code></p>
<p>注意还有关闭窗口操作</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 关闭子窗口</span><br><span class="line">web.close()</span><br><span class="line">#返回到原来的窗口</span><br><span class="line">web.switch_to.window(web.window_handles[0])</span><br></pre></td></tr></table></figure>

<p>完整代码：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># 窗口切换</span><br><span class="line">from selenium.webdriver import Firefox</span><br><span class="line">from selenium.webdriver.common.by import By</span><br><span class="line">import time</span><br><span class="line">from selenium.webdriver.common.keys import Keys</span><br><span class="line"></span><br><span class="line">web = Firefox()</span><br><span class="line"></span><br><span class="line">web.get(&#x27;https://www.lagou.com&#x27;)</span><br><span class="line">web.find_element(By.XPATH, r&#x27;//*[@id=&quot;cboxClose&quot;]&#x27;).click()</span><br><span class="line">time.sleep(1)</span><br><span class="line">web.find_element(By.XPATH, r&#x27;//*[@id=&quot;search_input&quot;]&#x27;).send_keys(&#x27;python&#x27;, Keys.ENTER)</span><br><span class="line">time.sleep(2)</span><br><span class="line">web.find_element(By.XPATH, r&#x27;/html/body/div/div[2]/div/div[3]/div[3]/div/div[1]/div[1]/div[1]/div[1]/div[1]/a&#x27;).click()</span><br><span class="line"># 此时已经进入一个新页面      #变成登录页面了。。。  </span><br><span class="line"># 如何进入到新窗口中进行提取</span><br><span class="line"># 注意，在selenium的眼中，新窗口是不会自动切换的</span><br><span class="line">web.switch_to.window(web.window_handles[-1])   # window_handles就是浏览器上面那个窗口</span><br><span class="line"># 在新窗口中提取内容。。。</span><br><span class="line"></span><br><span class="line"># 关闭子窗口</span><br><span class="line">web.close()</span><br><span class="line">#返回到原来的窗口</span><br><span class="line">web.switch_to.window(web.window_handles[0])</span><br></pre></td></tr></table></figure>
  </div>
</article>



        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
        
          <li><a href="/">Home</a></li>
        
          <li><a href="/about/">About</a></li>
        
          <li><a href="/archives/">Article</a></li>
        
          <li><a href="/tags/">Tag</a></li>
        
          <li><a href="/categories/">Category</a></li>
        
          <li><a href="/search/">Search</a></li>
        
      </ul>
    </div>

    
    
      <div id="toc-footer" style="display: none">
        <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%9D%E5%A7%8B%E7%88%AC%E8%99%AB"><span class="toc-number">1.</span> <span class="toc-text">初始爬虫</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8"><span class="toc-number">1.1.</span> <span class="toc-text">爬虫入门</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#web%E8%AF%B7%E6%B1%82%E8%BF%87%E7%A8%8B%E5%89%96%E6%9E%90"><span class="toc-number">1.2.</span> <span class="toc-text">web请求过程剖析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#http%E5%8D%8F%E8%AE%AE"><span class="toc-number">1.3.</span> <span class="toc-text">http协议</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#requests%E5%85%A5%E9%97%A8"><span class="toc-number">1.4.</span> <span class="toc-text">requests入门</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%88%AC%E5%8F%96%E7%99%BE%E5%BA%A6%E7%BF%BB%E8%AF%91%E6%95%B0%E6%8D%AE"><span class="toc-number">1.5.</span> <span class="toc-text">爬取百度翻译数据</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A1%A5%EF%BC%9A%E7%BC%96%E7%A0%81%E4%B8%8E%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99"><span class="toc-number">1.6.</span> <span class="toc-text">补：编码与文件读写</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%A7%A3-%E6%9E%90%E6%A6%82%E8%BF%B0"><span class="toc-number">2.</span> <span class="toc-text">数据解 析概述</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#re%E8%A7%A3%E6%9E%90"><span class="toc-number">2.1.</span> <span class="toc-text">re解析</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Regular-Expression-re"><span class="toc-number">2.1.1.</span> <span class="toc-text">Regular Expression(re)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#re%E6%A8%A1%E5%9D%97"><span class="toc-number">2.1.2.</span> <span class="toc-text">re模块</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#re%E6%A8%A1%E5%9D%97%E5%AE%9E%E6%88%98"><span class="toc-number">2.1.3.</span> <span class="toc-text">re模块实战</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E7%88%AC%E5%8F%96%E8%B1%86%E7%93%A3%E6%8E%92%E8%A1%8C%E6%A6%9Ctop250"><span class="toc-number">2.1.3.1.</span> <span class="toc-text">爬取豆瓣排行榜top250</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E7%88%AC%E5%8F%96%E7%94%B5%E5%BD%B1%E5%A4%A9%E5%A0%82%E4%BF%A1%E6%81%AF"><span class="toc-number">2.1.3.2.</span> <span class="toc-text">爬取电影天堂信息</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#bs4%E8%A7%A3%E6%9E%90"><span class="toc-number">2.2.</span> <span class="toc-text">bs4解析</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BB%83%E4%B9%A0"><span class="toc-number">2.2.1.</span> <span class="toc-text">练习</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%8C%97%E4%BA%AC%E6%96%B0%E5%8F%91%E5%9C%B0%E7%88%AC%E5%8F%96%E8%8F%9C%E4%BB%B7"><span class="toc-number">2.2.1.1.</span> <span class="toc-text">北京新发地爬取菜价</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E4%BC%98%E7%BE%8E%E7%BE%8E%E5%9B%BE%E5%BA%93%E5%9B%BE%E7%89%87"><span class="toc-number">2.2.1.2.</span> <span class="toc-text">优美美图库图片</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#xpath%E8%A7%A3%E6%9E%90"><span class="toc-number">2.3.</span> <span class="toc-text">xpath解析</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80"><span class="toc-number">2.3.0.1.</span> <span class="toc-text">基础</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%AE%9E%E6%88%98"><span class="toc-number">2.3.0.2.</span> <span class="toc-text">实战</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Requests-%E8%BF%9B%E9%98%B6"><span class="toc-number"></span> <span class="toc-text">Requests 进阶</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%84%E7%90%86cookie"><span class="toc-number">1.</span> <span class="toc-text">处理cookie</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%98%B2%E7%9B%97%E9%93%BE"><span class="toc-number">2.</span> <span class="toc-text">防盗链</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%9B%97%E9%93%BE"><span class="toc-number">2.0.1.</span> <span class="toc-text">盗链</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%98%B2%E7%9B%97%E9%93%BE%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="toc-number">2.0.2.</span> <span class="toc-text">防盗链的工作原理</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%A3%E7%90%86"><span class="toc-number">3.</span> <span class="toc-text">代理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BB%BC%E5%90%88%E8%AE%AD%E7%BB%83%EF%BC%88wyy%EF%BC%89"><span class="toc-number">4.</span> <span class="toc-text">综合训练（wyy）</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%88%AC%E5%8F%96%E7%BD%91%E6%98%93%E4%BA%91%E7%83%AD%E8%AF%84"><span class="toc-number">4.0.1.</span> <span class="toc-text">爬取网易云热评</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8F%90%E9%AB%98%E7%88%AC%E8%99%AB%E6%95%88%E7%8E%87"><span class="toc-number"></span> <span class="toc-text">提高爬虫效率</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E7%BA%BF%E7%A8%8B"><span class="toc-number">0.1.</span> <span class="toc-text">多线程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%A4%9A%E8%BF%9B%E7%A8%8B"><span class="toc-number">0.2.</span> <span class="toc-text">多进程</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%92%8C%E8%BF%9B%E7%A8%8B%E6%B1%A0"><span class="toc-number">0.3.</span> <span class="toc-text">线程池和进程池</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8D%8F%E7%A8%8B"><span class="toc-number">0.4.</span> <span class="toc-text">协程</span></a><ol class="toc-child"><li class="toc-item toc-level-6"><a class="toc-link" href="#%E9%98%BB%E5%A1%9E%E7%8A%B6%E6%80%81"><span class="toc-number">0.4.0.1.</span> <span class="toc-text">阻塞状态</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%8D%8F%E7%A8%8B-1"><span class="toc-number">0.4.0.2.</span> <span class="toc-text">协程</span></a></li><li class="toc-item toc-level-6"><a class="toc-link" href="#%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%BC%82%E6%AD%A5%E5%8D%8F%E7%A8%8B"><span class="toc-number">0.4.0.3.</span> <span class="toc-text">多任务异步协程</span></a></li></ol></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BC%82%E6%AD%A5http%E8%AF%B7%E6%B1%82aiohttp%E6%A8%A1%E5%9D%97"><span class="toc-number">0.5.</span> <span class="toc-text">异步http请求aiohttp模块</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%8A%93%E5%8F%96%E7%99%BE%E5%BA%A6%E5%B0%8F%E8%AF%B4-dd"><span class="toc-number">0.5.1.</span> <span class="toc-text">抓取百度小说(dd)</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%8A%93%E5%8F%96%E8%A7%86%E9%A2%91%E7%BD%91%E7%AB%99-dd"><span class="toc-number">0.5.2.</span> <span class="toc-text">抓取视频网站(dd)</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#selenium"><span class="toc-number"></span> <span class="toc-text">_selenium</span></a>
      </div>
    

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=http://p5ych2022.github.io/2023/05/22/python-spider/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=http://p5ych2022.github.io/2023/05/22/python-spider/&text=python spider"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=http://p5ych2022.github.io/2023/05/22/python-spider/&title=python spider"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=http://p5ych2022.github.io/2023/05/22/python-spider/&is_video=false&description=python spider"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=python spider&body=Check out this article: http://p5ych2022.github.io/2023/05/22/python-spider/"><i class="fa-solid fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=http://p5ych2022.github.io/2023/05/22/python-spider/&title=python spider"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=http://p5ych2022.github.io/2023/05/22/python-spider/&title=python spider"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=http://p5ych2022.github.io/2023/05/22/python-spider/&title=python spider"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=http://p5ych2022.github.io/2023/05/22/python-spider/&title=python spider"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=http://p5ych2022.github.io/2023/05/22/python-spider/&name=python spider&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=http://p5ych2022.github.io/2023/05/22/python-spider/&t=python spider"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fa-solid fa-bars fa-lg" aria-hidden="true"></i> Menu</a>
        
          <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fa-solid fa-list fa-lg" aria-hidden="true"></i> TOC</a>
        
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fa-solid fa-share-alt fa-lg" aria-hidden="true"></i> Share</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up fa-lg" aria-hidden="true"></i> Top</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2022-2024
    psych
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        <!--
       --><li><a href="/">Home</a></li><!--
     --><!--
       --><li><a href="/about/">About</a></li><!--
     --><!--
       --><li><a href="/archives/">Article</a></li><!--
     --><!--
       --><li><a href="/tags/">Tag</a></li><!--
     --><!--
       --><li><a href="/categories/">Category</a></li><!--
     --><!--
       --><li><a href="/search/">Search</a></li><!--
     -->
      </ul>
    </nav>
  </div>
</footer>
    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>


    <!-- jquery -->

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script>




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script>
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"Copy to clipboard!\">";
    btn += '<i class="fa-regular fa-clone"></i>';
    btn += '</span>';
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "Copied!");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

</body>
</html>
